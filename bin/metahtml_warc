#!/usr/bin/python3
'''
'''

# the sys import is needed so that we can import from the current project
import sys
sys.path.append('.')
import metahtml

# load imports
import gzip
import json
import sqlalchemy
import tempfile
import traceback
from warcio.archiveiterator import ArchiveIterator
import wget


def process_all_warcs_from_url(connection, cc_url):
    with tempfile.TemporaryDirectory() as tempdir:
        logging.info('downloading url '+cc_url+' to '+tempdir)
        cc_path = wget.download(cc_url, out=tempdir)
        with gzip.open(cc_path, 'rt') as f:
            for line in f:
                prefix = 'https://commoncrawl.s3.amazonaws.com/'
                warc_url = prefix+line.strip()
                logging.info("warc_url="+warc_url)
                process_warc_from_url(connection, warc_url)


def process_warc_from_url(connection, warc_url):
    '''
    FIXME:
    ideally, this function would be wrapped in a transaction;
    but this causes deadlocks when it is run concurrently with other instances of itself
    '''
    # create a new entry in the source table for this bulk insertion
    try:
        sql = sqlalchemy.sql.text('''
        INSERT INTO source (name) VALUES (:name) RETURNING id;
        ''')
        res = connection.execute(sql,{'name':warc_url})
        id_source = res.first()['id']
        logging.info('id_source='+str(id_source))

    # if an entry already exists in source,
    # then we have already inserted this warc and can safely skip the file
    except sqlalchemy.exc.IntegrityError:
        logging.info('skipping warc_url='+warc_url)
        return

    # process the warc file in a temporary directory;
    # the downloaded warc file will be stored in this directory and automatically deleted 
    with tempfile.TemporaryDirectory() as tempdir:
        logging.info('downloading url '+warc_url+' to '+tempdir)
        warc_path = wget.download(warc_url, out=tempdir)
        return process_warc_from_disk(connection, warc_path, id_source)


def process_warc_from_disk(connection, warc_path, id_source):
    '''
    FIXME:
    ideally, this function would be wrapped in a transaction;
    but this causes deadlocks when it is run concurrently with other instances of itself
    '''
    with open(warc_path, 'rb') as stream:
        for record in ArchiveIterator(stream):
            if record.rec_type == 'response':

                # extract the information from the warc archive
                url = record.rec_headers.get_header('WARC-Target-URI')
                accessed_at = record.rec_headers.get_header('WARC-Date')
                html = record.content_stream().read()
                logging.debug("url="+url)

                # extract the meta
                try:
                    meta = metahtml.parse(html, url)

                # if there was an error in metahtml, log it
                except Exception as e:
                    logging.warning('url='+url+' exception='+str(e))
                    meta = { 
                        'exception' : {
                            'str(e)' : str(e),
                            'type' : type(e).__name__,
                            'location' : 'metahtml',
                            'traceback' : traceback.format_exc()
                            }
                        }

                # insert into database
                try:
                    meta_json = json.dumps(meta, default=str)
                    sql = sqlalchemy.sql.text('''
                        INSERT INTO metahtml (accessed_at, id_source, url, jsonb) VALUES 
                            (:accessed_at, :id_source, :url, :jsonb);
                        ''')
                    res = connection.execute(sql,{
                        'accessed_at' : accessed_at,
                        'id_source' : id_source,
                        'url' : url,
                        'jsonb' : meta_json
                        })

                # if there was an error while inserting, log it
                except Exception as e:
                    logging.warning('url='+url+' exception='+str(e))
                    meta = { 
                        'exception' : {
                            'str(e)' : str(e),
                            'type' : type(e).__name__,
                            'location' : 'metahtml',
                            'traceback' : traceback.format_exc()
                            }
                        }
                    meta_json = json.dumps(meta, default=str)
                    sql = sqlalchemy.sql.text('''
                        INSERT INTO metahtml (accessed_at, id_source, url, jsonb) VALUES 
                            (:accessed_at, :id_source, :url, :jsonb);
                        ''')
                    res = connection.execute(sql,{
                        'accessed_at' : accessed_at,
                        'id_source' : id_source,
                        'url' : url,
                        'jsonb' : meta_json
                        })


if __name__ == '__main__':
    # process command line args
    import argparse
    parser = argparse.ArgumentParser(description='''
    Insert the warc file into the database.
    ''')
    parser.add_argument('--warc', help='warc file to insert into the db; may be either a file path or a url')
    parser.add_argument('--cc_url') 
    parser.add_argument('--db', default='postgresql:///')
    args = parser.parse_args()

    import logging
    logging.basicConfig(level=logging.INFO)

    # create database connection
    engine = sqlalchemy.create_engine(args.db, connect_args={
        'application_name': 'metahtml',
        })  
    connection = engine.connect()

    if args.warc:
        process_warc_from_url(connection,args.warc)

    if args.cc_url:
        process_all_warcs_from_url(connection, args.cc_url)
